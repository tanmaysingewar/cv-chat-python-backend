#helping functions related to read, write and publish model metrics
#utils
import requests
import os

from dotenv import load_dotenv
load_dotenv()
from openai import OpenAI

def call_groq_api(prompt,model="meta-llama/llama-3.1-70b-instruct"):
    """
    Calls the Novita AI API to interact with a specified language model, sending a prompt 
    and retrieving the model's response.

    Args:
        prompt (str): The text prompt to send to the model.
        model (str): The model to use for generating responses. Default is "meta-llama/llama-3.1-70b-instruct".

    Returns:
        str: The response content generated by the model.

    Raises:
        Exception: If there is an issue with the API call or response.

    Example:
        Input:
            prompt = "What is the capital of India?"
            model = "meta-llama/llama-3.1-70b-instruct"

        Output:
            "The capital of India is New Delhi."
    """
    client = OpenAI(
        base_url="https://api.novita.ai/v3/openai",
        # Get the Novita AI API Key by referring to: https://novita.ai/docs/get-started/quickstart.html#_2-manage-api-key.
        api_key= os.getenv("NOVITA_API_KEY"),
    )

    # Selecting the default model
    model = "meta-llama/llama-3.1-70b-instruct"

    # Stream the response False
    stream = False 

    # Chat completion API call
    chat_completion_res = client.chat.completions.create(
        model=model,
        messages=[
             {
                "role": "user",
                "content": prompt
            }
        ],
        stream=stream,
    )

    # Return the response
    return chat_completion_res.choices[0].message.content

_all_ = [
    "call_groq_api"
]
